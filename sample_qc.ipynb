{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dxpy # dxpy allows python to interact with the platform storage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7c12d",
   "metadata": {},
   "source": [
    "# Load dataset descriptions\n",
    "Output: entity_dictionary.csv, data_dictionary.csv, coding_dictionary.csv \\\n",
    "Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset descriptions\n",
    "\n",
    "# dxpy.find_one_data_object() searches for an object of type 'Dataset' in the root folder '/' whose name matches the wildcard pattern 'app*.dataset'.\n",
    "# And returns a dictionary describing the metadata of that dataset object.\n",
    "dispensed_dataset = dxpy.find_one_data_object(typename='Dataset', name='app*.dataset', folder='/', name_mode='glob')\n",
    "dispensed_dataset_id = dispensed_dataset['id']\n",
    "\n",
    "# dxpy.find_one_project() finds the current DNAnexus project, and returns a dictionary describing the metadata of the project.\n",
    "project_id = dxpy.find_one_project()['id']\n",
    "\n",
    "# Get DNAnexus dataset path 'project-xxxx:dataset-xxxx'\n",
    "dataset = (':').join([project_id, dispensed_dataset_id])\n",
    "\n",
    "# Extract the entire dataset and create three dictionary files that describe it:\n",
    "# entity_dictionary.csv that contains the list of entities (tables) available. There is a participant table that contains information per participant.\n",
    "# data_dictionary.csv that contains the list of fields (UK Biobank variable IDs) and which entity (table) they belong to.\n",
    "# coding_dictionary.csv that contains a lookup table mapping coded numeric values to their human-readable meanings for some of the fields.\n",
    "\n",
    "cmd = ['dx', 'extract_dataset', dataset, '-ddd', '--delimiter', ',']\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8748bd7",
   "metadata": {},
   "source": [
    "# Load cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load cohorts\n",
    "\n",
    "# Search for objects with criteria, take the first object, extract its unique DNAnexus object ID 'object-xxxx'\n",
    "dispensed_control_id = list(\n",
    "    dxpy.find_data_objects(typename='CohortBrowser', folder='/My/Cohorts', name_mode='exact', name='ischemic_controls',)\n",
    ")[0]['id']\n",
    "dispensed_case_id = list(\n",
    "    dxpy.find_data_objects(typename='CohortBrowser', folder='/My/Cohorts', name_mode='exact', name='ischemic_cases',)\n",
    ")[0]['id']\n",
    "\n",
    "# Get DNAnexus path for cohort 'project-xxxx:object-xxxx'\n",
    "control_dataset = (':').join([project_id, dispensed_control_id])\n",
    "case_dataset = (':').join([project_id, dispensed_case_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153bbb62",
   "metadata": {},
   "source": [
    "# Retrieve phenotype data as a dataframe\n",
    "Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve phenotype data\n",
    "field_ids = [\n",
    "    '31', # Sex\n",
    "    '2966', # Age high blood pressure diagnosed\n",
    "    '22001', # Genetic sex\n",
    "    '22006', # Genetic ethnic grouping\n",
    "    '22019', # Sex chromosome aneuploidy\n",
    "    '22021', # Genetic kinship to other participants\n",
    "    '21022', # Age at recruitment\n",
    "    '22027', # Outliers for heterozygosity or missing rate\n",
    "    '23104', # Body mass index (BMI)\n",
    "    '20160', # Ever smoked\n",
    "    '30760', # HDL cholesterol\n",
    "    '30780', # LDL direct\n",
    "    '22020', # Used in genetic principal components\n",
    "    '22009' # Genetic principal components\n",
    "]\n",
    "\n",
    "# Load data_dictionary.csv into a Pandas dataframe\n",
    "path = os.getcwd()\n",
    "data_dict_csv = glob.glob(os.path.join(path, '*.data_dictionary.csv'))[0]\n",
    "data_dict_df = pd.read_csv(data_dict_csv)\n",
    "\n",
    "data_dict_df.head()\n",
    "\n",
    "def fields_for_id(field_id):\n",
    "    '''Collect all field names (e.g. 'p<field_id>_iYYY_aZZZ') given a list of field IDs and return string to pass into extract_dataset'''\n",
    "    field_names = ['eid'] # participant id should be included\n",
    "    # Loop through every field ID, use regex to find col names corresponding to the field ID, extract them as a list \n",
    "    for _id in field_id:\n",
    "        select_field_names = list(\n",
    "            data_dict_df[\n",
    "                data_dict_df.name.str.match(r'^p{}(_i\\d+)?(_a\\d+)?$'.format(_id))\n",
    "            ].name.values\n",
    "        )\n",
    "        # For field '22009' PCA, select the first 10 PCs\n",
    "        if _id == '22009':\n",
    "            field_names += select_field_names[:10]\n",
    "        # For all fields except '2966' Age high blood pressure diagnosed, select only the first instance\n",
    "        elif _id != '2966' and len(select_field_names) > 1:\n",
    "            field_names += select_field_names[:1]\n",
    "        # For field '2966' Age high blood pressure diagnosed, select all instances\n",
    "        else:\n",
    "            field_names += select_field_names\n",
    "\t\t# Qualify each field name with participant data table -> ['participant.eid', 'participant.p31_i0_a0', ...]\n",
    "    field_names = [f'participant.{f}' for f in field_names] \n",
    "    # Combine all field names into one comma-delimited string so it can be passed to extract_dataset, return the string -> 'participant.eid,participant.p31_i0_a0,...'\n",
    "    return ','.join(field_names)\n",
    "    \n",
    "field_names = fields_for_id(field_ids) \n",
    "field_names \n",
    "\n",
    "print(field_names) # There should be no space separating the different fields in the string\n",
    "\n",
    "# Extract participant-level data for selected fields as control_dictionary.csv and case_dictionary.csv\n",
    "cmd = ['dx', 'extract_dataset', control_dataset, \n",
    "\t\t'--fields', field_names, \n",
    "\t\t'--delimiter', ',', \n",
    "\t\t'--output', 'control_dictionary.csv',\n",
    "]\n",
    "subprocess.check_call(cmd)\n",
    "cmd = ['dx', 'extract_dataset', case_dataset,\n",
    "    '--fields', field_names,\n",
    "    '--delimiter', ',',\n",
    "    '--output', 'case_dictionary.csv',\n",
    "]\n",
    "subprocess.check_call(cmd)\n",
    "\n",
    "# Convert to Pandas dataframe, removes that prefix in col headers using regex substitution\n",
    "# Note: re.sub('participant.', '', x) in original code is not precise. Unescaped dot represents 'any character' in regex.\n",
    "control_df = pd.read_csv('control_dictionary.csv')\n",
    "control_df = control_df.rename(columns=lambda x: re.sub(r'^participant\\.', '', x)) \n",
    "case_df = pd.read_csv('case_dictionary.csv')\n",
    "case_df = case_df.rename(columns=lambda x: re.sub(r'^participant\\.', '', x)) \n",
    "\n",
    "# Create target phenotype variable, combine cases and controls into a single Pandas dataframe\n",
    "case_df['ischemia_cc'] = 1\n",
    "control_df['ischemia_cc'] = 0\n",
    "df = pd.concat([case_df, control_df])\n",
    "\n",
    "df.head()\n",
    "print(df.shape)\n",
    "df.ischemia_cc.value_counts() # The counts should be consistent with the counts from Cohort Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799d070",
   "metadata": {},
   "source": [
    "# Sample QC and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ddc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample QC and imputation\n",
    "\n",
    "df_qced = df[\n",
    "    (df['p31'] == df['p22001']) # Filter reported sex and genetic sex are the same\n",
    "    & (df['p22006'] == 1)  # Only include Caucasian ancestry (In_white_british_ancestry_subset)\n",
    "    & (df['p22019'].isnull()) # No Sex chromosome aneuploidy\n",
    "    & (df['p22020'] == 1)  # Participant was used to calculate PCA \n",
    "    & (df['p22027'].isnull())    # exclude samples flagged as heterozygosity or missingness outliers\n",
    "].copy()\n",
    "\n",
    "df_qced.head()\n",
    "df_qced.ischemia_cc.value_counts()\n",
    "\n",
    "# Aggregate multiple instances of '2966' Age high blood pressure diagnosed into one binary variable\n",
    "df_qced['hypertension'] = [\n",
    "    np.nansum([float(row[i]) for i in [0, 1, 2, 3]]) > 0\n",
    "    for row in df_qced[['p2966_i0', 'p2966_i1', 'p2966_i2', 'p2966_i3']].to_numpy()\n",
    "]\n",
    "df_qced['hypertension'] = df_qced['hypertension'].astype(int)\n",
    "\n",
    "# Impute missing values for '20160' Ever smoked as 0\n",
    "# Note: df_qced['p20160_i0'].fillna(0, inplace=True) in original code get a view (not copy) of the df slice, inplace=True may not modify the df slice as intended.\n",
    "df_qced['p20160_i0'] = df_qced['p20160_i0'].fillna(0)\n",
    "\n",
    "# Impute missing values for '23104' BMI, '30760' HDL cholesterol, '30780' LDL direct with mean value\n",
    "df_qced['p23104_i0'] = df_qced['p23104_i0'].fillna(df_qced['p23104_i0'].mean())\n",
    "df_qced['p30760_i0'] = df_qced['p30760_i0'].fillna(df_qced['p30760_i0'].mean())\n",
    "df_qced['p30780_i0'] = df_qced['p30780_i0'].fillna(df_qced['p30780_i0'].mean())\n",
    "\n",
    "# Check that there are no missing values\n",
    "df_qced.isna().sum()\n",
    "\n",
    "# Rename PC cols and core phenotype cols\n",
    "df_qced = df_qced.rename(columns=lambda x: re.sub('p22009_a','pc',x))\n",
    "df_qced = df_qced.rename(\n",
    "    columns={\n",
    "        'eid': 'IID',\n",
    "        'p31': 'sex',\n",
    "        'p21022': 'age',\n",
    "        'p20160_i0': 'ever_smoked',\n",
    "        'p23104_i0': 'bmi',\n",
    "        'p30760_i0': 'hdl_cholesterol',\n",
    "        'p30780_i0': 'ldl_cholesterol',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add FID column, required input format for PLINK and Regenie\n",
    "df_qced['FID'] = df_qced['IID']\n",
    "\n",
    "# Create a file for target phenotype and covariates that can be used in Regenie (--phenoFile/--covarFile)\n",
    "cols = ['FID', 'IID', 'sex', 'age', 'bmi', 'ever_smoked', 'hdl_cholesterol', 'ldl_cholesterol', 'hypertension', 'ischemia_cc',]\n",
    "cols.extend([col for col in df_qced if 'pc' in col])\n",
    "df_phenotype = df_qced[cols]\n",
    "\n",
    "df_phenotype.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de844a93",
   "metadata": {},
   "source": [
    "# Select only samples with genotype imputation available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6adc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select only samples with genotype imputation available\n",
    "# Intersect the phenotype file and the imputation sample file based on IID, drop redundant cols\n",
    "# Note: Original code reads c1.sample file. It is changed to c22.sample here to save memory.\n",
    "# Note: sep='\\s' in original code is not standard python escape sequence. Use the raw string r'\\s+' instead.\n",
    "path_to_impute_file = f'/mnt/project/Bulk/Imputation/Imputation from genotype (GEL)/ukb21008_c22_b0_v1.sample' \n",
    "sample_file = pd.read_csv(path_to_impute_file, sep=r'\\s+', header=0, names=['FID', 'IID', 'missing', 'sex'], engine='python',)\n",
    "\n",
    "ischemia_df = df_phenotype.join(sample_file.set_index('IID'), on='IID', rsuffix='_sample', how='inner')\n",
    "ischemia_df.drop(columns=['FID_sample', 'missing', 'sex_sample'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83099998",
   "metadata": {},
   "source": [
    "# Write phenotype file to a tsv file with suffix .phe and upload to RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write phenotype files to a TSV file ischemia_df.phe and upload to RAP\n",
    "ischemia_df.to_csv('ischemia_df.phe', sep='\\t', na_rep='NA', index=False, quoting=3)\n",
    "ischemia_df.head()\n",
    "\n",
    "output_dir = '/My/Data/'\n",
    "\n",
    "subprocess.run([\n",
    "    \"dx\", \"upload\", \"ischemia_df.phe\",\n",
    "    \"-p\",\n",
    "    \"--path\", output_dir,\n",
    "    \"--brief\"\n",
    "])\n",
    "\n",
    "# Original code used a bash cell magic to upload the file:\n",
    "# %%bash -s \"$output_dir\"\n",
    "# dx upload ischemia_df.phe -p --path $1 --brief"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
